{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import required modules (make sure to pip install -r requirements.txt before this)\n",
        "import pinecone\n",
        "from google.colab import files\n",
        "import os\n",
        "import shutil\n",
        "from langchain.document_loaders import DirectoryLoader\n",
        "from langchain.embeddings import SentenceTransformerEmbeddings\n",
        "from langchain.vectorstores import Pinecone\n",
        "from langchain_pinecone import Pinecone  # Correct import\n",
        "from langchain.embeddings.openai import OpenAIEmbeddings  # Use OpenAI embeddings or SentenceTransformer"
      ],
      "metadata": {
        "id": "a1EJIdZuNHkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Uploading file\n",
        "uploaded = files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "CPqXkg03aPj4",
        "outputId": "27c9fdb5-e73b-4464-c938-c4ff23a65424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-ea0845dc-523a-4688-8be0-edfafe498fcc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-ea0845dc-523a-4688-8be0-edfafe498fcc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving proposal.pdf to proposal (5).pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the file path of the uploaded PDF\n",
        "pdf_path = list(uploaded.keys())[0]"
      ],
      "metadata": {
        "id": "cL2Uzu3CbesZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Extract text from the uploaded PDF file\n",
        "import PyPDF2\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    reader = PyPDF2.PdfReader(pdf_path)\n",
        "    text = ''\n",
        "    for page_num in range(len(reader.pages)):\n",
        "        text += reader.pages[page_num].extract_text()\n",
        "    return text"
      ],
      "metadata": {
        "id": "hzCbGxwybl4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract text from the PDF\n",
        "documents = extract_text_from_pdf(pdf_path)"
      ],
      "metadata": {
        "id": "M_7CfhAqbwI7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Split documents into chunks\n",
        "from langchain.schema import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Convert loaded documents into Document objects if they are strings\n",
        "def convert_to_document_objects(documents):\n",
        "    doc_objects = []\n",
        "    for doc in documents:\n",
        "        if isinstance(doc, str):\n",
        "            doc_objects.append(Document(page_content=doc))  # Ensure documents are converted to Document objects\n",
        "        else:\n",
        "            doc_objects.append(doc)\n",
        "    return doc_objects\n",
        "\n",
        "# Split documents into smaller chunks\n",
        "def split_docs(documents, chunk_size=500, chunk_overlap=20):  # Adjusted sizes for better context\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
        "    docs = text_splitter.split_documents(documents)\n",
        "    return docs\n",
        "\n",
        "# Ensure that the input document is valid\n",
        "if isinstance(documents, str):\n",
        "    documents = [documents]  # Ensure it's a list of documents\n",
        "\n",
        "# Convert documents to objects with page_content\n",
        "doc_objects = convert_to_document_objects(documents)  # Use doc_objects instead of raw strings\n",
        "\n",
        "# Check for the conversion result\n",
        "print(f\"Converted {len(doc_objects)} documents to Document objects.\")\n",
        "\n",
        "# Now split the documents\n",
        "docs = split_docs(doc_objects)  # Pass doc_objects to split_docs\n",
        "\n",
        "# Check result\n",
        "print(f\"Total chunks created: {len(docs)}\")\n",
        "for i in range(min(5, len(docs))):  # Display the first 5 chunks to check the result\n",
        "    print(f\"Chunk {i + 1}:\\n{docs[i].page_content}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_oDjJhOGiGvq",
        "outputId": "41d8052a-4e45-4e53-ee5f-0a1e97ddae63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converted 1 documents to Document objects.\n",
            "Total chunks created: 54\n",
            "Chunk 1:\n",
            "1 \n",
            " \n",
            "â€œStudy Of AI Strategies of Selected Organizations And Their Societal \n",
            "Impact With Special Reference  To India \" \n",
            " \n",
            "1) Introduction  \n",
            " \n",
            "Artificial Intelligence (AI)  \n",
            "Today's age is the age of Artificial Intelligence. AI has become \n",
            "increasingly prevalent across industries and sectors due to rapid \n",
            "advancements in computing power, algorithms, and big data. AI refers \n",
            "to computer systems that can perform tasks that typically require\n",
            "\n",
            "Chunk 2:\n",
            "human intelligence, such as visual perception, speech recognition, \n",
            "decision -making, a nd language translation.  \n",
            " \n",
            "The tech sector plays a key role in the development and deployment \n",
            "of AI technologies. In technologically advanced countries like the \n",
            "United States, AI is driving innovation and economic growth. Due to \n",
            "the rapid progress in machin e learning, neural networks, and other AI \n",
            "techniques, many industries are undergoing an AI revolution.\n",
            "\n",
            "Chunk 3:\n",
            "Dramatic changes have been observed across sectors like healthcare, \n",
            "finance, manufacturing, and transportation due to the application of \n",
            "AI technologies.  Use of AI -powered chatbots, recommendation \n",
            "systems, autonomous vehicles, medical imaging analysis, and robotic \n",
            "process automation are some of the novelties enabled by modern AI \n",
            "capabilities.  \n",
            " \n",
            "AI has many forms like Machine Learning, Deep Learning, Natural  \n",
            "Language Processing, Computer Vision, and Robotics. It is simply the\n",
            "\n",
            "Chunk 4:\n",
            "use of computer systems to perform tasks that normally require \n",
            "human intelligence. Several types of AI applications through which 2 \n",
            " \n",
            "users can access information and carry out tasks such as  image \n",
            "recognition, language translation, predictive analytics, and decision \n",
            "support without direct human involvement.  \n",
            " \n",
            "Modern AI techniques like deep learning were introduced in the 1980s \n",
            "but their widespread adoption across industries took place in the\n",
            "\n",
            "Chunk 5:\n",
            "2010s. The United States and China have been leaders in AI research \n",
            "and development. The AI revolution has connected previously isolated \n",
            "systems and enabled new capabilities that were not possible before. \n",
            "To access and benefit from AI -powered systems, users  typically need \n",
            "internet -connected devices and applications. The credentials and \n",
            "interfaces for AI systems are normally tailored for specific use cases, \n",
            "from voice assistants to enterprise AI platforms.  \n",
            " \n",
            "Genesis of AI\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Initialize the embeddings model\n",
        "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb2y8fkvcom1",
        "outputId": "659a1c12-4033-4106-a335-1ad289fd40f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-2f01879b9e9f>:2: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:90: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Initialize Pinecone\n",
        "from pinecone import Pinecone\n",
        "\n",
        "# Initialize Pinecone using your API key\n",
        "pc = Pinecone(\n",
        "    api_key=\"d79317b9-680b-4166-8bb4-4cb913892719\"  # Replace with your actual API key\n",
        ")\n",
        "\n",
        "# Define the index name you already created\n",
        "index_name = \"langchain-chatbot\"  # Ensure this matches the name of the index in the Pinecone UI\n",
        "\n",
        "# Access the existing index\n",
        "index = pc.Index(index_name)\n",
        "\n",
        "# Ensure you have initialized the index before inserting vectors\n",
        "\n",
        "# Step 6: Generate embeddings for the documents and insert them into Pinecone\n",
        "doc_texts = [doc.page_content for doc in docs]  # Extract the text from each document chunk\n",
        "doc_embeddings = embeddings.embed_documents(doc_texts)  # Generate embeddings for each document chunk\n",
        "\n",
        "\n",
        "# Prepare metadata (optional)\n",
        "metadata = [{\"id\": str(i), \"text\": doc.page_content} for i, doc in enumerate(docs)]  # Generate metadata for each document\n",
        "\n",
        "# Debugging: Check lengths\n",
        "print(f\"Number of document embeddings: {len(doc_embeddings)}\")\n",
        "print(f\"Number of metadata entries: {len(metadata)}\")\n",
        "\n",
        "# Ensure both lengths match\n",
        "if len(doc_embeddings) != len(metadata):\n",
        "    print(\"Warning: Lengths of embeddings and metadata do not match!\")\n",
        "\n",
        "# Prepare vectors with IDs and metadata\n",
        "vectors = []\n",
        "for i in range(len(doc_embeddings)):\n",
        "    # Ensure you are within bounds\n",
        "    if i < len(metadata):\n",
        "        vectors.append((str(i), doc_embeddings[i], metadata[i]))\n",
        "    else:\n",
        "        print(f\"Skipping index {i} due to missing metadata.\")\n",
        "\n",
        "# Function to batch the vectors into smaller chunks\n",
        "def batch_vectors(vectors, batch_size=100):\n",
        "    for i in range(0, len(vectors), batch_size):\n",
        "        yield vectors[i:i + batch_size]\n",
        "\n",
        "# Upsert vectors into Pinecone in batches\n",
        "batch_size = 100  # Adjust based on the size of your vectors and Pinecone limits\n",
        "for batch in batch_vectors(vectors, batch_size=batch_size):\n",
        "    index.upsert(vectors=batch)  # Insert vectors in batches\n",
        "\n",
        "print(f\"Successfully inserted {len(vectors)} vectors into Pinecone.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orQOtb4t9mjD",
        "outputId": "1dbc0cd0-e7ec-47a5-b158-b85cccba8f1e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of document embeddings: 54\n",
            "Number of metadata entries: 54\n",
            "Successfully inserted 54 vectors into Pinecone.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Function to search for similar documents\n",
        "def get_similar_docs(query, k=5, score=False):\n",
        "    # Generate query embeddings\n",
        "    query_embedding = embeddings.embed_query(query)  # Ensure it's a single string\n",
        "\n",
        "    # Perform similarity search with or without scores\n",
        "    if score:\n",
        "        similar_docs = index.query(vector=query_embedding, top_k=k, include_metadata=True)  # Use keyword arguments\n",
        "    else:\n",
        "        similar_docs = index.query(vector=query_embedding, top_k=k)\n",
        "\n",
        "    return similar_docs\n",
        "\n",
        "# Example query\n",
        "query = \"will ai have any impacts on jobs?\"\n",
        "results = get_similar_docs(query, k=5, score=True)  # Adjust k to retrieve more documents\n",
        "\n",
        "# Display the results\n",
        "for match in results['matches']:\n",
        "    # Check for the attributes present in match\n",
        "    match_id = match.get('id', 'No ID')\n",
        "    match_score = match.get('score', 'No Score')\n",
        "    match_metadata = match.get('metadata', {}).get('text', 'No Text')  # Use get to avoid KeyError\n",
        "\n",
        "    print(f\"ID: {match_id}, Score: {match_score}, Text: {match_metadata}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ru2W8ux1lgPb",
        "outputId": "af4ac14c-bae2-4872-f00f-21dc9b168800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ID: 33, Score: 0.719475925, Text: amplifying existing societal challenges rather th an solving them.  \n",
            " \n",
            "In summary, the literature reveals a spectrum of views on whether AI \n",
            "is good or bad. While some emphasize its potential for societal benefit \n",
            "and innovation, others caution against its risks, such as job \n",
            "displacement, bias, and loss of con trol. Most scholars agree, however, \n",
            "that the impact of AI will largely depend on how it is governed and \n",
            "whether ethical principles are incorporated into its development and\n",
            "ID: 15, Score: 0.670440793, Text: 1) Job displacement due to automation of routine cognitive and \n",
            "manual tasks  \n",
            "2) Exacerbation of economic inequality if benefits of AI accrue mainly \n",
            "to skilled workers and capital owners  \n",
            "3) Algorithmic  bias leading to unfair outcomes for certain groups  \n",
            "4) Privacy and data protection risks from AI systems that process \n",
            "personal data  6 \n",
            " \n",
            "5) Safety risks from autonomous AI systems in critical domains  \n",
            "6) Potential for AI to be misused for surveillance, manipulati on, or \n",
            "warfare\n",
            "ID: 24, Score: 0.644241571, Text: insights  \n",
            " \n",
            "7) Review of Literature  \n",
            " \n",
            "The societal impact and ethical considerations of Artificial Intelligence \n",
            "(AI) have been a focal point of research and debate over recent \n",
            "decades. Scholars, industry experts, and policy makers have explored \n",
            "AI's potentia l benefits and risks across various domains, leading to \n",
            "diverse perspectives on whether AI is inherently good or bad.  \n",
            " \n",
            "Russell and Norvig (2009) provide a foundational understanding of AI\n",
            "ID: 7, Score: 0.634227395, Text: across a wide range of tasks.  \n",
            " \n",
            "Countries like the United States, China, and the European Union have \n",
            "developed national AI strategies and are investing heavily in research \n",
            "and development. There are ongoing debates about the economic \n",
            "impacts, ethics, and safety considerations of increasingly capable AI \n",
            "systems. Some customers and industries have rapidly adopted AI due \n",
            "to its potential for automation, efficiency gains, and novel  capabilities.\n",
            "ID: 21, Score: 0.608669639, Text: innovation  \n",
            "10. To make a comparative analysis of AI's impact across different \n",
            "sectors/regions  \n",
            " \n",
            "5) Statement of Hypothesis  \n",
            " \n",
            "1. Demographic variables (age, education, profession, income) \n",
            "influence attitudes towards AI  \n",
            "2. There is no relationship between AI expectations and type of \n",
            "industry/sector  \n",
            "3. There is no relationship between preference for using A I and \n",
            "geographic location  \n",
            "4. Accessibility, transparency, fairness and safety have significant \n",
            "effect on AI acceptance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "xYVEAFmSsb7r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}